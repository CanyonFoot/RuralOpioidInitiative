{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enter info about the pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages: 1422\n"
     ]
    }
   ],
   "source": [
    "pdfFileObj = open('directory_2017.pdf', 'rb')\n",
    "pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
    "print(\"Number of pages:\", pdfReader.numPages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrape key to facility codes\n",
    "- 2 problems to solve if accurate key info is needed (right now just using the list of abbr.): \n",
    "    - titles of sections?\n",
    "    - lines for value are sometimes splitted thus not included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbr_key = {}\n",
    "def clean_key_page(raw_abbr_key):\n",
    "    raw_abbr_key[:] = [l for l in raw_abbr_key if (l.strip()!= '')]\n",
    "    i = 0\n",
    "    while i < len(raw_abbr_key):\n",
    "        #print(raw_abbr_key[i])\n",
    "        if raw_abbr_key[i].isupper():\n",
    "            abbr_key[raw_abbr_key[i].strip()] = raw_abbr_key[i+1].strip()\n",
    "            i += 2\n",
    "        else:\n",
    "            spitted = raw_abbr_key[i].split()\n",
    "            if spitted[0].isupper():\n",
    "                abbr_key[spitted[0]] = ', '.join(spitted[1:])\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_abbr_key1 = pdfReader.getPage(4).extractText()\n",
    "raw_abbr_key1 = raw_abbr_key1.split('\\n')\n",
    "raw_abbr_key1 = raw_abbr_key1[1:len(raw_abbr_key1) - 4]\n",
    "clean_key_page(raw_abbr_key1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_abbr_key2 = pdfReader.getPage(5).extractText()\n",
    "raw_abbr_key2 = raw_abbr_key2.split('\\n')\n",
    "raw_abbr_key2 = raw_abbr_key2[:len(raw_abbr_key2) - 4]\n",
    "clean_key_page(raw_abbr_key2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_abbr_key3 = pdfReader.getPage(6).extractText()\n",
    "raw_abbr_key3 = raw_abbr_key3.split('\\n')\n",
    "raw_abbr_key3 = raw_abbr_key3[26:len(raw_abbr_key3)-1]\n",
    "clean_key_page(raw_abbr_key3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GHF': 'General Health Services',\n",
       " 'MHF': 'Mental Health Treatment Services',\n",
       " 'MHSAF': 'Mix of Mental Health and Substance Abuse',\n",
       " 'SAF': 'Substance Abuse Treatment Services',\n",
       " 'ACM': 'Acamprosate (Campral®)',\n",
       " 'BM': 'Buprenorphine, maintenance',\n",
       " 'BMW': 'Buprenorphine, maintenance, for, a, pre-',\n",
       " 'BU': 'Buprenorphine, used, in, treatment',\n",
       " 'DB': 'Buprenorphine, detoxi˝cation',\n",
       " 'DM': 'Methadone, detoxi˝cation',\n",
       " 'DSF': 'Disul˝ram (Antabuse®)',\n",
       " 'DT': 'Detoxi˝cation',\n",
       " 'HH': 'Transitional, housing, or, halfway, house',\n",
       " 'METH': 'Methadone',\n",
       " 'MM': 'Methadone maintenance',\n",
       " 'MMW': 'Methadone maintenance for pre-determined',\n",
       " 'MOA': 'Accepts clients on opioid medication',\n",
       " 'MPD': 'Medications for psychiatric disorders',\n",
       " 'NMOA': 'Does not use medication for opioid addiction',\n",
       " 'NOOP': 'Does not treat opioid addiction',\n",
       " 'NXN': 'Naltrexone, (oral)',\n",
       " 'OTP': 'SAMHSA-certi˝ed Opioid Treatment Program',\n",
       " 'OTPA': 'All clients in Opioid Treatment Program',\n",
       " 'PAIN': 'Use methadone/buprenorphine for pain',\n",
       " 'RPN': 'Relapse prevention with naltrexone',\n",
       " 'SA': 'Substance abuse treatment',\n",
       " 'UBN': 'Prescribes/administers buprenorphine and/or',\n",
       " 'VTRL': 'Extended-release, injectable naltrexone',\n",
       " 'ANG': 'Anger, management',\n",
       " 'BIA': 'Brief intervention',\n",
       " 'CBT': 'Cognitive behavioral therapy',\n",
       " 'CMI': 'Contingency management/motivational',\n",
       " 'CRV': 'Community reinforcement plus vouchers',\n",
       " 'DBT': 'Dialectical behavioral therapy',\n",
       " 'MOTI': 'Motivational interviewing',\n",
       " 'MXM': 'Matrix Model',\n",
       " 'REBT': 'Rational emotive behavioral therapy',\n",
       " 'RELP': 'Relapse prevention',\n",
       " 'SACA': 'Substance abuse counseling',\n",
       " 'TRC': 'Trauma-related counseling',\n",
       " 'TWFA': '12-step facilitation',\n",
       " 'SMON': 'Smoking not permitted',\n",
       " 'SMOP': 'Smoking permitted without restriction',\n",
       " 'SMPD': 'Smoking permitted in designated area',\n",
       " 'CT': 'Computerized, treatment',\n",
       " 'GH': 'General, hospital, (including, VA, hospital)',\n",
       " 'HI': 'Hospital, inpatient',\n",
       " 'HID': 'Hospital, inpatient, detoxi˝cation',\n",
       " 'HIT': 'Hospital inpatient treatment',\n",
       " 'OD': 'Outpatient, detoxi˝cation',\n",
       " 'ODT': 'Outpatient day treatment or partial',\n",
       " 'OIT': 'Intensive outpatient treatment',\n",
       " 'OMB': 'Outpatient methadone/buprenorphine or',\n",
       " 'OP': 'Outpatient',\n",
       " 'ORT': 'Regular outpatient treatment',\n",
       " 'PH': 'Partial, hospitalization/day, treatment',\n",
       " 'PSYH': 'Psychiatric hospital',\n",
       " 'RD': 'Residential, detoxi˝cation',\n",
       " 'RES': 'Residential',\n",
       " 'RL': 'Long-term, residential, (more, than, 30, days)',\n",
       " 'RS': 'Short-term, residential, (30, days, or, less)',\n",
       " 'DDF': 'Department, of, Defense',\n",
       " 'IH': 'Indian, Health, Service',\n",
       " 'LCCG': 'Local, county, or community government',\n",
       " 'PVT': 'Private organization',\n",
       " 'STG': 'State government',\n",
       " 'TBG': 'Tribal government',\n",
       " 'VAMC': 'U.S. Department of Veterans A˙airs',\n",
       " 'ATR': 'Access to Recovery (ATR) vouchers',\n",
       " 'FSA': 'Federal, or any government funding for',\n",
       " 'ITU': 'IHS/Tribal/Urban (ITU) funds',\n",
       " 'MC': 'Medicare',\n",
       " 'MD': 'Medicaid',\n",
       " 'MI': 'Military, insurance, (e.g.,, VA,, TRICARE)',\n",
       " 'NP': 'No, payment, accepted',\n",
       " 'PI': 'Private, health, insurance',\n",
       " 'SF': 'Cash, or, self-payment',\n",
       " 'SI': 'State, ˝nanced, insurance, (other, than, Medicaid)',\n",
       " 'PA': 'Payment, assistance, (check, with, facility, for',\n",
       " 'SS': 'Sliding, fee, scale, (fee, is, based, on, income, and',\n",
       " 'AD': 'Adolescents',\n",
       " 'ADM': 'Active duty military',\n",
       " 'CJ': 'Criminal, justice, clients',\n",
       " 'CO': 'Persons, with, co-occurring, mental, and, substance',\n",
       " 'DV': 'Persons, who, have, experienced, domestic, violence',\n",
       " 'GL': 'Lesbian,, gay,, bisexual,, or, transgender, (LGBT)',\n",
       " 'HV': 'Persons, with, HIV/AIDS',\n",
       " 'MF': 'Military, families',\n",
       " 'MN': 'Adult, men',\n",
       " 'PW': 'Pregnant/postpartum, women',\n",
       " 'SE': 'Seniors/older, adults',\n",
       " 'TAY': 'Transitional age young adults',\n",
       " 'TRMA': 'Persons who have experienced trauma',\n",
       " 'VET': 'Veterans',\n",
       " 'WN': 'Adult, women',\n",
       " 'XA': 'Persons, who, have, experienced, sexual, abuse',\n",
       " 'CARF': 'Commission on Accreditation of Rehabilitation',\n",
       " 'COA': 'Council on Accreditation',\n",
       " 'HFAP': 'Healthcare Facilities Accreditation Program',\n",
       " 'HLA': 'Hospital licensing authority',\n",
       " 'JC': '˜e, Joint, Commission',\n",
       " 'NCQA': 'National Committee for ˚uality Assurance',\n",
       " 'STAG': 'State substance abuse agency',\n",
       " 'STDH': 'State department of health',\n",
       " 'STMH': 'State mental health department',\n",
       " 'ADLT': 'Adults',\n",
       " 'CHLD': 'Children/adolescents',\n",
       " 'YAD': 'Young adults',\n",
       " 'FEM': 'Female',\n",
       " 'MALE': 'Male',\n",
       " 'BMO': 'Methadone and buprenorphine clients only',\n",
       " 'DU': 'DUI/DWI, clients',\n",
       " 'DUO': 'Serves, only, DUI/DWI, clients',\n",
       " 'MO': 'Methadone, clients, only',\n",
       " 'ACC': 'Aˆercare/continuing care',\n",
       " 'ACU': 'Acupuncture',\n",
       " 'ADD': 'Treatment for non-substance abuse addiction',\n",
       " 'ADTX': 'Alcohol detoxi˝cation',\n",
       " 'AOSS': 'Assistance with obtaining social services',\n",
       " 'BABA': 'Breath analyzer for blood alcohol testing',\n",
       " 'BC': 'Residential, beds, for, clients™, children',\n",
       " 'BDTX': 'Benzodiazepines detoxi˝cation',\n",
       " 'CCC': 'Child, care, for, clients™, children',\n",
       " 'CDTX': 'Cocaine detoxi˝cation',\n",
       " 'CM': 'Case, management',\n",
       " 'CSAA': 'Comprehensive mental health assessment',\n",
       " 'DAUT': 'Drug or alcohol urine screening',\n",
       " 'DP': 'Discharge, planning',\n",
       " 'DVFP': 'Domestic violence servicesŠfamily or partner',\n",
       " 'EIH': 'Early intervention for HIV',\n",
       " 'EMP': 'Employment counseling or training',\n",
       " 'FCO': 'Family counseling o˙ered',\n",
       " 'GCO': 'Group counseling o˙ered',\n",
       " 'HAEC': 'HIV or AIDS education, counseling, or support',\n",
       " 'HEOH': 'Health education services other than HIV/',\n",
       " 'AIDS': 'or, hepatitis',\n",
       " 'HIVT': 'HIV testing',\n",
       " 'HS': 'Housing, services',\n",
       " 'ICO': 'Individual counseling o˙ered',\n",
       " 'ISC': 'Interim services for clients',\n",
       " 'MCO': 'Marital/couples counseling o˙ered',\n",
       " 'MDTX': 'Methamphetamine detoxi˝cation',\n",
       " 'MHS': 'Mental health services',\n",
       " 'NRT': 'Nicotine replacement therapy',\n",
       " 'NSC': 'Non-nicotine smoking/tobacco cessation',\n",
       " 'ODTX': 'Opioid detoxi˝cation',\n",
       " 'OPC': 'Outreach to persons in the community',\n",
       " 'PEER': 'Consumer-run (peer support services)',\n",
       " 'SAE': 'Substance abuse education',\n",
       " 'SHB': 'Screening for Hepatitis B',\n",
       " 'SHC': 'Screening for Hepatitis C',\n",
       " 'SHG': 'Self-help groups',\n",
       " 'SMHD': 'Screening for mental health disorders',\n",
       " 'SSA': 'Screening for substance abuse',\n",
       " 'SSD': 'Social skills development',\n",
       " 'STDT': 'STD testing',\n",
       " 'STU': 'Screening for tobacco use',\n",
       " 'TA': 'Transportation, assistance',\n",
       " 'TAEC': 'Hepatitis education, counseling, or support',\n",
       " 'TBS': 'TB screening',\n",
       " 'TCC': 'Smoking/tobacco cessation counseling',\n",
       " 'TGD': 'Treatment for gambling disorder',\n",
       " 'TID': 'Treatment for Internet use disorder',\n",
       " 'AH': 'Assistance for the deaf and hard of hearing (may be provided by either sta˙ counselor or on-call interpreter)',\n",
       " 'N65': 'Aleut',\n",
       " 'N73': 'Anishinaabemowin',\n",
       " 'N4': 'Cherokee',\n",
       " 'N5': 'Cheyenne',\n",
       " 'N75': 'Chickasaw',\n",
       " 'N7': 'Cocopah',\n",
       " 'N9': 'Crow',\n",
       " 'N76': 'Gwichin',\n",
       " 'N42': 'Haida',\n",
       " 'N13': 'Hopi',\n",
       " 'N70': 'Inupiaq',\n",
       " 'N16': 'Keres',\n",
       " 'N18': 'Lakota',\n",
       " 'N22': 'Mohawk',\n",
       " 'N23': 'Navajo',\n",
       " 'N24': 'Ojibwa',\n",
       " 'N28': 'Passamaquoddy',\n",
       " 'N32': 'Shoshoni',\n",
       " 'N33': 'Tewa',\n",
       " 'N49': 'Tiwa',\n",
       " 'N34': 'Tlingit',\n",
       " 'N35': 'Tohono, O™odham',\n",
       " 'N36': 'Towa',\n",
       " 'N51': 'Triqui',\n",
       " 'N79': 'Tsimshian',\n",
       " 'N40': 'Yupik',\n",
       " 'N41': 'Zuni',\n",
       " 'F110': 'Akan',\n",
       " 'F2': 'Albanian',\n",
       " 'F3': 'Amharic',\n",
       " 'F4': 'Arabic',\n",
       " 'F5': 'Armenian',\n",
       " 'F6': 'Assyrian',\n",
       " 'F8': 'Belarusan',\n",
       " 'F9': 'Bengali',\n",
       " 'F161': 'Bisaya',\n",
       " 'F10': 'Bosnian',\n",
       " 'F11': 'Bulgarian',\n",
       " 'F12': 'Burmese',\n",
       " 'F151': 'Burundi',\n",
       " 'F105': 'Cebuano',\n",
       " 'F15': 'Chaldean',\n",
       " 'F17': 'Chinese',\n",
       " 'F18': 'Chuukese',\n",
       " 'F19': 'Creole',\n",
       " 'F20': 'Croatian',\n",
       " 'F21': 'Czech',\n",
       " 'F22': 'Danish',\n",
       " 'F98': 'Dari',\n",
       " 'F23': 'Dutch',\n",
       " 'F132': 'Dzongkha',\n",
       " 'F102': 'EdoF25, Farsi',\n",
       " 'F26': 'Fijian',\n",
       " 'F28': 'French',\n",
       " 'F165': 'Fula',\n",
       " 'F157': 'Georgian',\n",
       " 'F30': 'German',\n",
       " 'F31': 'Greek',\n",
       " 'F33': 'Gujurati',\n",
       " 'F108': 'Hausa',\n",
       " 'F34': 'Hawaiian',\n",
       " 'F35': 'Hebrew',\n",
       " 'F36': 'Hindi',\n",
       " 'F37': 'Hmong',\n",
       " 'F38': 'Hungarian',\n",
       " 'F147': 'Ibibio',\n",
       " 'F39': 'Igbo',\n",
       " 'F40': 'Ilocano',\n",
       " 'F164': 'Ilonggo',\n",
       " 'F42': 'Italian',\n",
       " 'F43': 'Japanese',\n",
       " 'F113': 'Kannada',\n",
       " 'F142': 'Karen',\n",
       " 'F44': 'Khmer',\n",
       " 'F45': 'Khmu',\n",
       " 'F46': 'Kinyarwand',\n",
       " 'F152': 'Kirundi',\n",
       " 'F47': 'Korean',\n",
       " 'F109': 'Krio',\n",
       " 'F135': 'Kurdish',\n",
       " 'F48': 'LaoF49, Latvian',\n",
       " 'F160': 'Lingala',\n",
       " 'F99': 'Lithuanian',\n",
       " 'F52': 'Macedonian',\n",
       " 'F163': 'Mai, Mai',\n",
       " 'F53': 'Malay',\n",
       " 'F54': 'Malayalam',\n",
       " 'F120': 'Mandinka',\n",
       " 'F119': 'Marathi',\n",
       " 'F58': 'Mien',\n",
       " 'F60': 'Mongolian',\n",
       " 'F61': 'Nepali',\n",
       " 'F62': 'Nigerian',\n",
       " 'F63': 'Norwegian',\n",
       " 'F167': 'Nuer',\n",
       " 'F153': 'Oroma',\n",
       " 'F64': 'Palauan',\n",
       " 'F118': 'Pashto,, Southern',\n",
       " 'F66': 'Polish',\n",
       " 'F67': 'Portuguese',\n",
       " 'F65': 'Punjabi',\n",
       " 'F68': '˚uiche',\n",
       " 'F69': 'Romanian',\n",
       " 'F70': 'Russian',\n",
       " 'F71': 'Samoan',\n",
       " 'F73': 'Serbian',\n",
       " 'F74': 'Serbian/Croatian',\n",
       " 'F75': 'Slavic',\n",
       " 'F76': 'Slovak',\n",
       " 'F104': 'Somali',\n",
       " 'SP': 'Spanish',\n",
       " 'F79': 'Swahili',\n",
       " 'F80': 'Swedish',\n",
       " 'F81': 'Tagalog',\n",
       " 'F166': 'Taishanese',\n",
       " 'F154': 'Taiwanese',\n",
       " 'F82': 'Tamil',\n",
       " 'F85': 'Telugu',\n",
       " 'F86': '˜ai',\n",
       " 'F141': 'Tigrinya',\n",
       " 'F87': 'Tongan',\n",
       " 'F88': 'Turkish',\n",
       " 'F89': 'Ukrainian',\n",
       " 'F91': 'Urdu',\n",
       " 'F92': 'Vietnamese',\n",
       " 'F144': 'Visayan',\n",
       " 'F94': 'Yapese',\n",
       " 'F95': 'Yiddish',\n",
       " 'F96': 'Yoruba',\n",
       " 'F159': 'Zulu'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abbr_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scraper test on a page of data\n",
    "- data starts on page 15 (getPage(14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(rawdata):\n",
    "    '''\n",
    "    Roughly split data, returns list of list.\n",
    "    Inputs:\n",
    "        rawdata_from_page(list): list of items on the page that were seperated by /n\n",
    "    '''\n",
    "    #split erroneously connected data\n",
    "    data = []\n",
    "    temp = []\n",
    "    i = 0\n",
    "    while i < len(rawdata) - 1:\n",
    "        #if i is the last line of keys, i+1 is facility name, i-1 is the phone number or other line of keys\n",
    "        if rawdata[i].isupper() and (rawdata[i].split()[0] in abbr_key) and \\\n",
    "        (not rawdata[i+1].isupper()) and (rawdata[i-1][0] == '(' or rawdata[i-1].isupper()): \n",
    "            temp.append(rawdata[i])\n",
    "            data.append(temp)\n",
    "            temp = []\n",
    "        else:\n",
    "            temp.append(rawdata[i])\n",
    "        i += 1\n",
    "    temp.append(rawdata[i])\n",
    "    data.append(temp)\n",
    "    return data\n",
    "\n",
    "\n",
    "def clean_facility_name(fname):\n",
    "    '''\n",
    "    Split facility name into [\"junk\", actual name]\n",
    "    fname(str): name of the facility\n",
    "    '''\n",
    "    front = ''\n",
    "    i = 0\n",
    "    while i < len(fname) - 1:\n",
    "        if (fname[i].isupper() or fname[i] == ' ')\\\n",
    "        and (fname[i+1].isupper() or fname[i+1] == ' '):\n",
    "            front += fname[i]\n",
    "            i += 1\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    if front in abbr_key:\n",
    "        return [front, fname[i:]]\n",
    "    \n",
    "    #if its just capitalized name...\n",
    "    elif front == 'YMCA' or front == 'BAART' or fname[i:i+3] == 'Inc':\n",
    "        return ['', fname]\n",
    "    #if it is accidentally included city name\n",
    "    else:\n",
    "        return ['', fname[i:]]\n",
    "    \n",
    "    \n",
    "def clean_all_facility_name(data):\n",
    "    '''\n",
    "    Move and link wrongly splitted data, changes in place\n",
    "    '''\n",
    "    i = 0\n",
    "    while i < len(data):\n",
    "        facility_name_raw = data[i][0]\n",
    "        if facility_name_raw[:2].isupper():\n",
    "            code, fac_name = clean_facility_name(facility_name_raw)\n",
    "            data[i][0] = fac_name\n",
    "            if i != 0:\n",
    "                data[i - 1].append(code)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_center_street(cn_sa, page):\n",
    "    '''\n",
    "    Split a string containing center name and street address into two.\n",
    "    Inputs:\n",
    "        cn_sa(str)\n",
    "    Returns: a list\n",
    "    '''\n",
    "    #Exception to split at number :\n",
    "        #When it ends with \"P.O. Box\",\n",
    "        #When the number being found is at the very front (wrongly included page number or \n",
    "        #center name starts with number)\n",
    "        \n",
    "    #If the number is at the end(suite xxx or building xxx) lets include the word in front of it)\n",
    "    #print(cn_sa)\n",
    "    #print(page)\n",
    "    if cn_sa[0].isnumeric():\n",
    "        temp = cn_sa.split()\n",
    "        if temp[0] == str(page):\n",
    "            cn_sa = ' '.join(temp[1:])\n",
    "            \n",
    "    m = re.finditer(r\"\\d+\", cn_sa)\n",
    "\n",
    "    for num in m:\n",
    "        span = num.span()\n",
    "        if span[0] != 0:    \n",
    "            if cn_sa[span[0] - 9:span[0] - 1] == 'P.O. Box':\n",
    "                return ([cn_sa[:span[0] - 10], cn_sa[span[0] - 9:]])\n",
    "            if span[1] != len(cn_sa):\n",
    "                return ([cn_sa[:span[0] - 1], cn_sa[span[0]:]])\n",
    "            if span[1] == len(cn_sa):\n",
    "                return ([' '.join(cn_sa.split()[:-2]), ' '.join(cn_sa.split()[-2:])])\n",
    "    return [cn_sa, '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data(data, year, page, filename):\n",
    "    '''\n",
    "    write data into right columns\n",
    "    '''\n",
    "    with open(filename, 'a', newline = '') as file:\n",
    "        writer = csv.writer(file)\n",
    "        #loop over centers\n",
    "        for dc in data:\n",
    "            #print(dc)##\n",
    "            i = 0\n",
    "            data_holder = [year, page]\n",
    "        #Center name, street address\n",
    "            cn_sa = ''\n",
    "            while (',' not in dc[i]) or not dc[i][-5:].isnumeric(): #(len(dc[i]) < 2) or \n",
    "                #print(i)##\n",
    "                cn_sa += ' ' + dc[i]\n",
    "                i += 1\n",
    "            data_holder += split_center_street(cn_sa.strip(), page)\n",
    "            #print(data_holder)\n",
    "                \n",
    "        #City, State, Postal_code\n",
    "            city, state_postcode = dc[i].split(',')\n",
    "            state, postcode = state_postcode.split()\n",
    "            data_holder += [city, state, postcode]\n",
    "            i += 1\n",
    "        #phone\n",
    "            phone = dc[i]\n",
    "            i += 1\n",
    "            while not dc[i][0:2].isupper():\n",
    "                phone += ' ' + dc[i]\n",
    "                i += 1\n",
    "            data_holder.append(phone)\n",
    "        #keys\n",
    "            data_holder.append(' '.join(dc[i:]))\n",
    "        #write data\n",
    "            writer.writerow(data_holder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on a bunch of pages\n",
    "- Implement a geograpy package to better clean data?\n",
    "- page 93 (BAART Programs) BAART is deleted because of the capitalization\n",
    "- Manually entered: \n",
    "    - 2017: page 885, 1206, 1334"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(dir_filename, year, start_page):\n",
    "    \n",
    "    #read file\n",
    "    pdfFileObj = open(dir_filename, 'rb')\n",
    "    pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
    "    \n",
    "    #pages to scrape\n",
    "    end_page = pdfReader.numPages - 1\n",
    "    \n",
    "    #open/create csv\n",
    "    save_as_filename = str(year) + '.csv'\n",
    "    if os.path.isfile(save_as_filename):\n",
    "        with open(save_as_filename, 'a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "    else:\n",
    "        with open(save_as_filename, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Year\", \"Page\", \"Center_name\", \"Street_address\", \"City\", \\\n",
    "                             \"State\", \"Postal_code\", \"Phone\", \"Keys\"])\n",
    "\n",
    "    for i in range(start_page, end_page + 1):\n",
    "        page = pdfReader.getPage(i).extractText()\n",
    "        rawdata = page.split('\\n')\n",
    "        #delete na lines\n",
    "        rawdata[:] = [l.strip() for l in rawdata if not (l.strip() == '' or l == 'KEY')]\n",
    "        #clean\n",
    "        if rawdata and not (rawdata == [str(i) + 'KEY']):\n",
    "            data = clean_data(rawdata)\n",
    "            clean_all_facility_name(data)\n",
    "            write_data(data, year, i, save_as_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "run('directory_2012.pdf', 2012, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "#debug purposes\n",
    "year = 2012\n",
    "pagen = 424\n",
    "filename = str(year)+'.csv'\n",
    "\n",
    "pdfFileObj = open('directory_{}.pdf'.format(str(year)), 'rb')\n",
    "pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
    "\n",
    "with open(filename, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Year\", \"Page\", \"Center_name\", \"Street_address\", \"City\", \"State\", \"Postal_code\", \"Phone\", \"Keys\"])\n",
    "\n",
    "page = pdfReader.getPage(pagen).extractText()\n",
    "rawdata = page.split('\\n')\n",
    "#delete na lines\n",
    "rawdata[:] = [l.strip() for l in rawdata if not (l.strip() == '' or l == 'KEY')]\n",
    "if rawdata and not (rawdata == [str(pagen) + 'KEY']):\n",
    "    data = clean_data(rawdata)\n",
    "    clean_all_facility_name(data)\n",
    "    write_data(data, year, pagen, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SAF SA DT ACM MPD NXN VTRL NMOA CBT DBT SACA TRC REBT TWFA BIA CMI MOTI ANG RELP  SMON RES OP RS RL RD OD ODT OIT PVT STAG STDH JC SF PI MI  CO GL VET ADM MF CJ SE WN MN HV TRMA XA DV TAY CM PEER HS NRT NSC STU TCC SSA SMHD CSAA CMHA BABA DAUT SHB SHC HIVT STDT TBS DP ACC SSD SAE TA MHS ACU SHG ADTX BDTX CDTX MDTX ODTX ICO GCO FCO MCO YAD ADLT FEMMALE'"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'SAFSA DT ACM MPD NXN VTRL NMOACBT DBT SACA TRC REBT TWFA BIA CMI MOTI ANG RELP SMONRES OP RS RL RD OD ODT OITPVTSTAG STDH JCSF PI MI CO GL VET ADM MF CJ SE WN MN HV TRMA XA DV TAYCM PEER HS NRT NSC STU TCC SSA SMHD CSAA CMHA BABA DAUT SHB SHC HIVT STDT TBS DP ACC SSD SAE TA MHS ACU SHG ADTX BDTX CDTX MDTX ODTX ICO GCO FCO MCOYAD ADLTFEMMALE'\n",
    "s.replace('', ' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
